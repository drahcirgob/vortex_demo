[
  {
    "id": "dia-00",
    "dayNumber": 0,
    "title": "Protocolo de Imersão",
    "subtitle": "As Leis do Laboratório",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d0_p01", "title": "Bem-vindo ao Cockpit", "type": "paragraph", "content": "Hoje você deixa de ser um mero passageiro e assume o cockpit. As regras a seguir não são conselhos, são o protocolo para uma performance de elite." },
      { "pillId": "d0_p02", "title": "Protocolos de Elite", "type": "sectionHeader", "content": "" },
      { "pillId": "d0_p03", "title": "Regra n°1: O Cronômetro é Sagrado", "type": "listItem", "content": "Cada bloco tem um início e um fim. A sua capacidade de respeitar estes limites é o primeiro passo para a disciplina profissional." },
      { "pillId": "d0_p04", "title": "Regra n°2: Imersão Total", "type": "listItem", "content": "Durante um bloco, o mundo exterior cessa de existir. Desligue tudo. Feche as abas irrelevantes. O seu foco é a sua maior ferramenta." },
      { "pillId": "d0_p05", "title": "Regra n°3: Recalibração Neural", "type": "listItem", "content": "As pausas são obrigatórias. Afaste-se da tela, hidrate-se, alongue-se. O seu cérebro precisa de tempo para consolidar o que aprendeu. É neurociência, não preguiça." },
      { "pillId": "d0_p06", "title": "Regra n°4: A Prova de Execução", "type": "listItem", "content": "O dia só termina quando o seu trabalho está versionado e seguro no seu portfólio. É a sua assinatura no trabalho do dia." }
    ]
  },
  {
    "id": "dia-01",
    "dayNumber": 1,
    "title": "A Arquitetura do Comando",
    "subtitle": "Da Conversa ao Código",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d1_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Modelos de Linguagem são motores de inferência. Nós não conversamos com motores, nós os operamos. Hoje, você aprende os painéis de controle, as alavancas e os medidores para extrair performance de precisão, não respostas vagas." },
      { "pillId": "d1_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Construir iterativamente um prompt de nível de produção que comanda um LLM a produzir uma saída JSON perfeitamente estruturada, validável e pronta para ser consumida por software." },
      { "pillId": "d1_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Conta Google Cloud" },
      { "pillId": "d1_p04", "title": "", "type": "listItem", "content": "Google AI Studio" },
      { "pillId": "d1_p05", "title": "", "type": "listItem", "content": "Git & GitHub" },
      { "pillId": "d1_p06", "title": "", "type": "listItem", "content": "Google Cloud Shell" },
      { "pillId": "d1_p07", "title": "Cronograma de Operações Detalhado", "type": "sectionHeader", "content": "Tempo Estimado: 9 Horas" },
      { "pillId": "d1_p08", "title": "Protocolo de Lançamento (Pré-Missão)", "type": "subHeader", "content": "" },
      { "pillId": "d1_p09", "title": "Nota do Redator", "type": "note", "content": "Esta seção é executada ANTES do cronômetro começar. O objetivo é eliminar 99% dos problemas de setup do ambiente. O dia só começa quando esta base estiver 100% operacional." },
      { "pillId": "d1_p10", "title": "O Caminho Dourado (Recomendado): Google Cloud Shell", "type": "paragraph", "content": "O Google Cloud Shell é um terminal com um editor de código (baseado no VS Code) que roda diretamente no seu navegador. Ele já vem com o Git, gcloud CLI e autenticação para o seu projeto configurados." },
      { "pillId": "d1_p11", "title": "Ative o Google Cloud", "type": "listItem", "content": "Acesse o Google Cloud Console. Crie seu projeto ia-bootcamp-ops e ative a Vertex AI API." },
      { "pillId": "d1_p12", "title": "Ação Crítica: Configure um Alerta de Orçamento para $10", "type": "listItem", "content": "Vá em Faturamento > Orçamentos e alertas. Não pule este passo." },
      { "pillId": "d1_p13", "title": "Inicie o Cloud Shell", "type": "listItem", "content": "No topo do Google Cloud Console, clique no ícone >_ (Ativar o Cloud Shell). Uma sessão de terminal será aberta na parte inferior da tela. Clique em 'Abrir Editor' para lançar a IDE completa em uma nova aba." },
      { "pillId": "d1_p14", "title": "Configure o Portfólio no Cloud Shell", "type": "code", "language": "bash", "content": "# O Git já está instalado e autenticado com sua conta Google\ngit config --global user.name \"Seu Nome\"\ngit config --global user.email \"seu.email@exemplo.com\"\n\n# Crie a estrutura\nmkdir ia-bootcamp-portfolio && cd ia-bootcamp-portfolio\ngit init\necho \"node_modules/\\n.env\" > .gitignore\ntouch .env" },
      { "pillId": "d1_p15", "title": "Crie seu Repositório Remoto no GitHub", "type": "listItem", "content": "Vá ao site do GitHub, crie o repositório ia-bootcamp-portfolio (público, sem README ou .gitignore)." },
      { "pillId": "d1_p16", "title": "Conecte o Repositório", "type": "code", "language": "bash", "content": "git remote add origin https://github.com/SEU_USUARIO/ia-bootcamp-portfolio.git" },
      { "pillId": "d1_p17", "title": "Bloco 1: Calibração de Comportamento (Persona & CoT)", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d1_p18", "title": "Pausa Tática e Almoço", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d1_p19", "title": "Bloco 2: Construção Iterativa do Prompt Mestre", "type": "sectionHeader", "content": "Duração: 4 Horas" },
      { "pillId": "d1_p20", "title": "Iteração 1: A Força Bruta (Resultado Inútil)", "type": "subHeader", "content": "" },
      { "pillId": "d1_p21", "title": "Prompt", "type": "prompt", "content": "Analise a empresa \"NVIDIA\" no setor de \"Semicondutores e IA\" e forneça uma análise SWOT em JSON.", "validationCriteria": { "prompt": "Cole o seu prompt da Iteração 1 aqui:", "type": "string_contains_all", "values": ["NVIDIA", "JSON"] } },
      { "pillId": "d1_p22", "title": "Análise Crítica", "type": "criticalAnalysis", "content": "A saída provavelmente será um JSON, mas desastroso. Chaves como \"Forças\" (com acento e maiúscula), valores como \"Marca forte e liderança em GPU\", preços como strings, etc. É imprevisível e quebraria qualquer software. Problema: Falta de estrutura e tipos de dados definidos." },
      { "pillId": "d1_p23", "title": "Iteração 2: Impondo Ordem (Schema Básico)", "type": "subHeader", "content": "" },
      { "pillId": "d1_p24", "title": "Prompt", "type": "prompt", "content": "Você é um assistente que gera JSON.\n\n### TAREFA ###\nAnalise a empresa e setor fornecidos e gere uma análise SWOT.\n\n### REGRAS DE SAÍDA ###\n- A saída DEVE ser um único bloco de código JSON.\n- NENHUM texto deve estar fora do bloco JSON.\n- O JSON DEVE seguir o schema abaixo.\n\n### JSON SCHEMA ###\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"empresa_analisada\": { \"type\": \"string\" },\n    \"analise_swot\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"forcas\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n        \"fraquezas\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n      }\n    }\n  }\n}\n\n### DADOS ###\n- Empresa: \"NVIDIA\"\n- Setor: \"Semicondutores e IA\"" },
      { "pillId": "d1_p25", "title": "Análise Crítica", "type": "criticalAnalysis", "content": "Melhora Drástica! A estrutura agora é previsível. As chaves estão corretas (forcas, não Forças). Os valores são arrays de strings. Problema: A qualidade do conteúdo ainda é superficial. As análises são genéricas (\"Marca forte\"). Como podemos tornar a análise mais profunda e o JSON mais rico?" },
      { "pillId": "d1_p26", "title": "Iteração 3: Adicionando Inteligência e Riqueza", "type": "subHeader", "content": "" },
      { "pillId": "d1_p27", "title": "Prompt Mestre", "type": "prompt", "content": "### PERFIL DA IA ###\nVocê é \"MarketMind\", um Analista de Inteligência de Mercado de elite. Sua especialidade é sintetizar dados complexos em análises SWOT. Você é preciso, factual e objetivo.\n\n### PROCESSO DE RACIOCÍNIO (Chain-of-Thought Interno) ###\nAntes de gerar a saída, siga estes passos mentais:\n1. Para cada pilar (Forças, Fraquezas, etc), identifique pontos específicos.\n2. Para cada ponto, forneça uma análise concisa de 1-2 frases.\n3. Para cada ponto, atribua um score de impacto de 1 a 10.\n\n### TAREFA, REGRAS DE SAÍDA E JSON SCHEMA ###\n(Combine com as seções da Iteração 2, mas agora o schema é mais rico, exigindo um objeto com \"ponto\", \"analise\" e \"impacto\" em vez de apenas uma string).\n\n### DADOS ###\n- Empresa: \"NVIDIA\"\n- Setor: \"Semicondutores e IA\"", "validationCriteria": { "prompt": "Cole o seu prompt mestre final aqui para validação:", "type": "string_contains_all", "values": ["PERFIL DA IA", "PROCESSO DE RACIOCÍNIO", "JSON SCHEMA"] } },
      { "pillId": "d1_p28", "title": "Análise Crítica", "type": "criticalAnalysis", "content": "Sucesso. Agora temos o resultado desejado. O JSON não é apenas bem formado, ele é rico em dados. A Persona e o CoT melhoraram a qualidade do conteúdo, enquanto o Schema garantiu a qualidade da estrutura. O aluno construiu isso passo a passo, entendendo a função de cada bloco de instrução." },
      { "pillId": "d1_p29", "title": "Bloco 3: Documentação e Prova de Execução", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d1_p30", "title": "Checklist de Encerramento", "type": "subHeader", "content": "" },
      { "pillId": "d1_p31", "title": "Organize os Artefatos", "type": "listItem", "content": "Crie a pasta dia-01-prompt-architecture/ e, dentro dela, os arquivos: iteracao_1_bruta.md, iteracao_2_estrutura.md, prompt_mestre_final.md, exemplo_output_final.json" },
      { "pillId": "d1_p32", "title": "Preencha os Arquivos", "type": "listItem", "content": "Em cada arquivo .md, cole o prompt correspondente. No prompt_mestre_final.md, adicione uma nota final. No exemplo_output_final.json, cole a saída JSON perfeita." },
      { "pillId": "d1_p33", "title": "Commite e Envie seu Trabalho", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-01): iteratively build advanced swot analysis prompt\"\ngit push -u origin main" },
      { "pillId": "d1_p34", "title": "Fim da Transmissão do Dia 1", "type": "finalAssessment", "content": "Você não apenas copiou um prompt. Você o construiu. Você diagnosticou falhas e aplicou a ferramenta correta para corrigi-las em cada etapa. Você agiu como um engenheiro. Descanse. Amanhã, vamos conectar este cérebro que você programou ao mundo exterior." }
    ]
  },
  {
    "id": "dia-02",
    "dayNumber": 2,
    "title": "Ativação de Ativos",
    "subtitle": "Da Teoria à Tração Global",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d2_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Um prompt brilhante num terminal é um troféu. Uma API que serve esse prompt globalmente, sob demanda e em escala, é uma arma. Hoje, você aprende a armar as suas ideias." },
      { "pillId": "d2_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Transformar o \"Prompt Mestre\" numa ferramenta de software real, interativa e serverless, usando uma stack de produção que separa corretamente os segredos do código e garante a integridade dos dados na camada da API." },
      { "pillId": "d2_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Firebase (Cloud Functions & Hosting)" },
      { "pillId": "d2_p04", "title": "", "type": "listItem", "content": "Node.js" },
      { "pillId": "d2_p05", "title": "", "type": "listItem", "content": "Google SDK para Gemini" },
      { "pillId": "d2_p06", "title": "", "type": "listItem", "content": "Google Cloud Shell/Terminal" },
      { "pillId": "d2_p07", "title": "", "type": "listItem", "content": "Git" },
      { "pillId": "d2_p08", "title": "Bloco 1: Setup da Infraestrutura Serverless", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d2_p09", "title": "Ambiente de Comando", "type": "subHeader", "content": "" },
      { "pillId": "d2_p10", "title": "Caminho Dourado (Recomendado)", "type": "paragraph", "content": "Continue usando o Google Cloud Shell do Dia 1. Ele já possui o firebase-tools instalado e autenticado." },
      { "pillId": "d2_p11", "title": "Inicialização do Projeto Firebase", "type": "subHeader", "content": "" },
      { "pillId": "d2_p12", "title": "Nota Importante", "type": "note", "content": "Navegue até o diretório raiz do seu projeto ia-bootcamp-portfolio." },
      { "pillId": "d2_p13", "title": "Execute a Inicialização", "type": "code", "language": "bash", "content": "firebase init" },
      { "pillId": "d2_p14", "title": "Pílula de Conhecimento: O que é 'Serverless'?", "type": "knowledgePill", "content": "\"Serverless\" não significa que não há servidores. Significa que você não os gerencia. Com as Cloud Functions, você escreve o código de backend e o Google trata de provisionar, escalar (de zero a milhares de requisições) e manter a infraestrutura. Você paga apenas pelos milissegundos em que seu código está realmente executando. É o ápice da eficiência operacional." },
      { "pillId": "d2_p15", "title": "Bloco 2: Construção do Backend de Produção", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d2_p16", "title": "Instalação das Dependências", "type": "code", "language": "bash", "content": "cd functions\nnpm install @google/generative-ai dotenv cors\ncd .. # Volte para a raiz" },
      { "pillId": "d2_p17", "title": "Gerenciamento de Segredos: O Padrão Profissional", "type": "subHeader", "content": "" },
      { "pillId": "d2_p18", "title": "Ambiente Local (Emulador)", "type": "paragraph", "content": "Crie um arquivo .env dentro da pasta functions e adicione sua chave: GOOGLE_API_KEY=\"SUA_CHAVE_DE_API_AQUI\". Garanta que seu .gitignore na raiz do projeto tenha a linha functions/.env." },
      { "pillId": "d2_p19", "title": "Ambiente de Produção (Nuvem)", "type": "paragraph", "content": "A nuvem não lê arquivos .env. Usamos a configuração de ambiente do Firebase. Execute o comando abaixo na raiz do projeto." },
      { "pillId": "d2_p20", "title": "Armazenar Chave na Nuvem", "type": "code", "language": "bash", "content": "firebase functions:config:set google.apikey=\"SUA_CHAVE_DE_API_AQUI\"" },
      { "pillId": "d2_p21", "title": "Código da Cloud Function", "type": "code", "language": "javascript", "content": "const functions = require(\"firebase-functions\");\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\nconst logger = require(\"firebase-functions/logger\");\nconst cors = require(\"cors\")({ origin: true });\n\nif (process.env.NODE_ENV !== \"production\") {\n  require(\"dotenv\").config();\n}\n\nconst apiKey = process.env.GOOGLE_API_KEY || functions.config().google.apikey;\nconst genAI = new GoogleGenerativeAI(apiKey);\n\nconst generationConfig = {\n  response_mime_type: \"application/json\",\n};\nconst model = genAI.getGenerativeModel({ model: \"gemini-pro\", generationConfig });\n\nexports.analistaDeMercado = functions.https.onRequest((request, response) => {\n  cors(request, response, async () => {\n    logger.info(\"Iniciando execução...\");\n\n    try {\n      if (request.method !== 'POST') {\n          return response.status(405).json({ error: \"Método não permitido. Use POST.\" });\n      }\n      const { empresa, setor } = request.body.data;\n      if (!empresa || !setor) {\n        logger.error(\"Erro: Input inválido.\");\n        return response.status(400).json({ error: \"Parâmetros 'empresa' e 'setor' são obrigatórios.\" });\n      }\n\n      const prompt = `Analise a empresa \"${empresa}\" no setor de \"${setor}\" e forneça uma análise SWOT detalhada, com pontos fortes, fracos, oportunidades e ameaças. Para cada ponto, forneça uma análise concisa e um score de impacto de 1 a 10.`;\n\n      const result = await model.generateContent(prompt);\n      const data = await result.response.text();\n\n      logger.info(\"Análise gerada com sucesso para: \" + empresa);\n      response.status(200).send({ data: JSON.parse(data) });\n\n    } catch (error) {\n      logger.error(\"Ocorreu um erro catastrófico\", error);\n      response.status(500).json({ error: \"Falha ao gerar análise.\" });\n    }\n  });\n});" },
      { "pillId": "d2_p22", "title": "Pausa Tática e Almoço", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d2_p23", "title": "Bloco 3: Construção e Teste da Interface Web", "type": "sectionHeader", "content": "Duração: 3 Horas" },
      { "pillId": "d2_p24", "title": "Teste Local com o Emulador Firebase", "type": "subHeader", "content": "" },
      { "pillId": "d2_p25", "title": "Iniciar Emulador", "type": "code", "language": "bash", "content": "firebase emulators:start" },
      { "pillId": "d2_p26", "title": "Bloco 4: Lançamento e Documentação Profissional", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d2_p27", "title": "Deploy - O Lançamento", "type": "code", "language": "bash", "content": "firebase deploy" },
      { "pillId": "d2_p28", "title": "A Dança do Deploy (Atualização da URL)", "type": "paragraph", "content": "Agora você tem a URL pública da sua API. Volte ao seu código em public/index.html e substitua a URL do emulador pela URL pública da sua função. Como apenas o frontend mudou, podemos fazer um deploy mais rápido." },
      { "pillId": "d2_p29", "title": "Deploy Rápido do Frontend", "type": "code", "language": "bash", "content": "firebase deploy --only hosting", "validationCriteria": { "prompt": "Após o deploy, cole a URL final da sua aplicação (Firebase Hosting URL):", "type": "url_matches_pattern", "pattern": "https://*.web.app" } },
      { "pillId": "d2_p30", "title": "Entregável do Dia: O Diário de Bordo do Engenheiro", "type": "subHeader", "content": "" },
      { "pillId": "d2_p31", "title": "Crie seu Diário", "type": "code", "language": "markdown", "content": "# Dia 2: Aplicação do Analista Estratégico\n\n## Link para a Aplicação Funcional\n\n[Analista Estratégico AI](URL_DO_SEU_HOSTING_AQUI)\n\n## Arquitetura da Solução\n\nA aplicação segue um padrão serverless full-stack:\n\n`[Utilizador]` -> `[Firebase Hosting (Frontend HTML/JS)]` -> `[Cloud Function (Backend Node.js)]` -> `[API do Gemini]`\n\n- **Firebase Hosting:** Serve os arquivos estáticos da interface do utilizador de forma global e rápida através de uma CDN.\n- **Cloud Functions:** Fornece o poder de computação do backend. Ela recebe a requisição do frontend, constrói o prompt, e gerencia a comunicação segura com a API do Gemini.\n- **Gemini API:** O cérebro da operação, que processa o prompt e retorna a análise de mercado.\n\n## Principais Lições e Desafios\n\n- **Gerenciamento de Segredos:** A principal lição foi a distinção crítica entre o gerenciamento de segredos para desenvolvimento local (`.env`) e para produção na nuvem (`firebase functions:config:set`).\n- **Imposição de Formato via API:** Mudar para a configuração `response_mime_type: \"application/json\"` na chamada da API do Gemini é uma melhoria massiva em robustez.\n- **Ciclo de Deploy:** O processo de deploy inicial para obter a URL da função e, em seguida, um segundo deploy para atualizar o frontend com essa URL, ilustra um ciclo comum no desenvolvimento serverless." },
      { "pillId": "d2_p32", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-02): deploy serverless strategic analyst app\ndocs(day-02): add architecture and learnings journal\"\ngit push origin main" },
      { "pillId": "d2_p33", "title": "Fim da Transmissão do Dia 2", "type": "finalAssessment", "content": "Operador, o seu ativo intelectual está agora operacional e foi construído com padrões de produção. Você não apenas criou uma aplicação, mas aprendeu a gerir a sua segurança e a garantir a sua robustez. Amanhã, a missão muda. Modelos de linguagem são poderosos, mas o seu verdadeiro poder vem dos dados. Vamos mergulhar na Engenharia de Dados para preparar o combustível dos nossos próprios modelos. Descanse. A extração começa ao amanhecer." }
    ]
  },
  {
    "id": "dia-03",
    "dayNumber": 3,
    "title": "Dados Como Combustível",
    "subtitle": "A Refinaria de Inteligência",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d3_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "A IA genérica é um mercenário; ele luta por qualquer um. Um modelo treinado com os seus dados é um soldado de elite leal à sua missão. Hoje, você não vai procurar dados, vai forjá-los. O princípio de \"Lixo entra, Lixo sai\" (Garbage In, Garbage Out) é a sua lei. A qualidade do seu modelo é um reflexo direto da qualidade do seu combustível." },
      { "pillId": "d3_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Ingerir, explorar, limpar e enriquecer um dataset do mundo real, transformando-o numa \"Tabela Dourada\" otimizada para treino de ML, usando o poder investigativo e transformador do SQL no BigQuery." },
      { "pillId": "d3_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Google Cloud (BigQuery)" },
      { "pillId": "d3_p04", "title": "", "type": "listItem", "content": "SQL (com foco em Agregação, CTEs e Funções de Janela)" },
      { "pillId": "d3_p05", "title": "", "type": "listItem", "content": "Kaggle" },
      { "pillId": "d3_p06", "title": "Bloco 1: Extração e Carga (ELT - A Fase 'EL')", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d3_p07", "title": "Aquisição de Inteligência Bruta (Kaggle)", "type": "subHeader", "content": "Vá para Kaggle.com. Procure e baixe o dataset \"Women's E-Commerce Clothing Reviews\". Link: https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews. Descomprima o .zip para obter o arquivo .csv." },
      { "pillId": "d3_p08", "title": "Preparação da Base no BigQuery", "type": "subHeader", "content": "Acesse o Google Cloud Console e navegue para o BigQuery. Crie um novo dataset: ID bootcamp_ecommerce, Localização US (multiple regions)." },
      { "pillId": "d3_p09", "title": "Carga do Material Bruto", "type": "subHeader", "content": "Crie uma nova tabela dentro do seu dataset. Fonte: Upload do seu arquivo .csv. Nome da Tabela: reviews_raw. Schema: Marque \"Auto detect\". Opções Avançadas: Header rows to skip -> 1. Clique em Create table." },
      { "pillId": "d3_p10", "title": "Pílula de Conhecimento: ELT vs. ETL", "type": "knowledgePill", "content": "No passado, o padrão era ETL (Extract, Transform, Load). Com ferramentas como o BigQuery, o padrão moderno é ELT (Extract, Load, Transform). Nós carregamos os dados brutos primeiro (Load) e usamos o poder computacional massivo da nuvem para os transformar (Transform) no local. É mais rápido, escalável e mantém um registro imutável dos dados originais." },
      { "pillId": "d3_p11", "title": "Bloco 2: Análise Exploratória de Dados (EDA com SQL)", "type": "sectionHeader", "content": "Duração: 2 Horas" },
      { "pillId": "d3_p12", "title": "Query 1: Contagem de Nulos por Coluna", "type": "subHeader", "content": "Pergunta: Onde estão os buracos nos meus dados?" },
      { "pillId": "d3_p13", "title": "Inspeção de Nulos", "type": "code", "language": "sql", "content": "-- Vamos inspecionar cada coluna para ver a contagem de valores nulos.\nSELECT\n  COUNTIF(`Clothing ID` IS NULL) AS nulos_id_produto,\n  COUNTIF(Title IS NULL) AS nulos_titulo,\n  COUNTIF(`Review Text` IS NULL) AS nulos_texto_review,\n  COUNTIF(`Division Name` IS NULL) AS nulos_divisao\nFROM `ia-bootcamp-ops.bootcamp_ecommerce.reviews_raw`;" },
      { "pillId": "d3_p14", "title": "Análise", "type": "criticalAnalysis", "content": "Você descobrirá que Title e Review Text têm milhares de nulos. Isto informa a nossa decisão de usar COALESCE mais tarde. A coluna Division Name também tem alguns." },
      { "pillId": "d3_p15", "title": "Query 2: Distribuição dos Ratings", "type": "subHeader", "content": "Pergunta: Os clientes estão geralmente satisfeitos ou insatisfeitos?" },
      { "pillId": "d3_p16", "title": "Distribuição de Ratings", "type": "code", "language": "sql", "content": "-- Vamos ver como os ratings de 1 a 5 estão distribuídos.\nSELECT\n  Rating,\n  COUNT(*) AS contagem_de_reviews\nFROM `ia-bootcamp-ops.bootcamp_ecommerce.reviews_raw`\nGROUP BY Rating\nORDER BY Rating ASC;" },
      { "pillId": "d3_p17", "title": "Análise", "type": "criticalAnalysis", "content": "Você notará que há muito mais reviews com ratings 4 e 5 do que 1 e 2. Isso é chamado de \"dataset desbalanceado\". É uma informação crucial para o treino de modelos de ML no futuro." },
      { "pillId": "d3_p18", "title": "Pausa Tática e Almoço", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d3_p19", "title": "Bloco 3: Pipeline de Transformação e Engenharia (A Fase 'T')", "type": "sectionHeader", "content": "Duração: 4 Horas" },
      { "pillId": "d3_p20", "title": "Pipeline de Transformação SQL", "type": "code", "language": "sql", "content": "-- ############################################################################\n-- ## Pipeline de Transformação de Dados para o Dataset de E-commerce Reviews ##\n-- ############################################################################\n-- Este script transforma a tabela `reviews_raw` numa `reviews_golden_table`\n-- otimizada para tarefas de Machine Learning, como análise de sentimento.\n\n-- Usamos Common Table Expressions (CTEs) para dividir o processo em passos lógicos.\n\n-- CTE 1: Seleção de Base e Renomeação\n-- Objetivo: Selecionar as colunas relevantes e dar-lhes nomes limpos e padronizados.\nWITH base_selection AS (\n  SELECT\n    `Clothing ID` AS id_produto,\n    Age AS idade,\n    Title AS titulo,\n    `Review Text` AS texto_review,\n    Rating AS rating,\n    `Recommended IND` AS recomendado,\n    `Positive Feedback Count` AS contagem_feedback_positivo,\n    `Division Name` AS nome_divisao,\n    `Department Name` AS nome_departamento,\n    `Class Name` AS nome_classe\n  FROM\n    `ia-bootcamp-ops.bootcamp_ecommerce.reviews_raw`\n),\n\n-- CTE 2: Limpeza, Tipagem e Tratamento de Nulos\n-- Objetivo: Corrigir tipos de dados e lidar com valores em falta (nulos) que identificámos na nossa análise exploratória.\ntype_casting_and_cleaning AS (\n  SELECT\n    -- Garantimos que o ID do produto é uma STRING para evitar que seja tratado como número.\n    CAST(id_produto AS STRING) AS id_produto,\n    idade,\n    \n    -- Se o título ou texto forem nulos, substituímo-los por um valor padrão.\n    -- COALESCE retorna o primeiro valor não-nulo da lista.\n    COALESCE(titulo, 'Sem Título') AS titulo,\n    COALESCE(texto_review, 'Sem Review') AS texto_review,\n    rating,\n    contagem_feedback_positivo,\n\n    -- Transformamos o indicador 0/1 numa coluna BOOLEANA (TRUE/FALSE), que é mais semântica.\n    CASE WHEN recomendado = 1 THEN TRUE ELSE FALSE END AS e_recomendado,\n\n    -- Lidamos com categorias nulas, atribuindo um valor padrão.\n    COALESCE(nome_divisao, 'Geral') AS divisao,\n    COALESCE(nome_departamento, 'Desconhecido') AS departamento,\n    COALESCE(nome_classe, 'Outros') AS classe\n  FROM\n    base_selection\n  -- Filtro crítico: Removemos reviews onde o texto é completamente nulo.\n  -- Estes registos são inúteis para um modelo de análise de texto.\n  WHERE `Review Text` IS NOT NULL\n),\n\n-- CTE 3: Engenharia de Features\n-- Objetivo: Criar novas colunas (features) a partir das existentes para dar mais sinais ao nosso futuro modelo de ML.\nfeature_engineering AS (\n  SELECT\n    *, -- Seleciona todas as colunas da CTE anterior para não perdermos nada\n\n    -- Feature 1: Sentimento (Nosso Alvo para ML - a \"variável target\").\n    -- Criamos categorias claras a partir do rating numérico.\n    CASE\n      WHEN rating >= 4 THEN 'Positivo'\n      WHEN rating <= 2 THEN 'Negativo'\n      ELSE 'Neutro'\n    END AS sentimento,\n\n    -- Feature 2: A review tem um título explícito?\n    -- Hipótese: Isto pode indicar um maior envolvimento do cliente.\n    (titulo != 'Sem Título') AS tem_titulo,\n    \n    -- Feature 3: Comprimento do texto do review.\n    -- Hipótese: Reviews mais longas podem conter mais detalhes e emoções mais fortes.\n    LENGTH(texto_review) AS tamanho_review,\n\n    -- Feature 4 (Avançada - Funções de Janela): Média de rating do departamento.\n    -- OVER(PARTITION BY ...) calcula uma agregação para cada \"grupo\" (partição) de linhas.\n    -- Hipótese: Um rating 4 num departamento com média 2.5 é um sinal mais forte do que um rating 4 num departamento com média 4.8. Fornece contexto.\n    ROUND(AVG(rating) OVER(PARTITION BY departamento), 2) AS media_rating_departamento\n\n  FROM\n    type_casting_and_cleaning\n)\n\n-- Seleção Final: Escolhemos todas as colunas da nossa CTE final de engenharia.\n-- Este é o formato final da nossa Tabela Dourada.\nSELECT * FROM feature_engineering;" },
      { "pillId": "d3_p21", "title": "Bloco 4: Materialização e Documentação", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d3_p22", "title": "Materialização da Tabela Dourada", "type": "subHeader", "content": "Com a sua query SQL final aberta no editor do BigQuery, clique no botão 'Salvar' e selecione 'Salvar como Tabela'. Preencha os detalhes: Projeto: ia-bootcamp-ops, Dataset: bootcamp_ecommerce, Nome da Tabela: reviews_golden_table. Clique em 'Executar'.", "validationCriteria": { "prompt": "Cole o nome completo da sua Tabela Dourada no BigQuery (ex: projeto.dataset.tabela):", "type": "string_equals", "value": "ia-bootcamp-ops.bootcamp_ecommerce.reviews_golden_table" } },
      { "pillId": "d3_p23", "title": "Organize seus Artefatos", "type": "subHeader", "content": "No seu repositório, crie a pasta dia-03-data-engineering e, dentro dela, os arquivos transform.sql e README.md." },
      { "pillId": "d3_p24", "title": "Preencha os Arquivos", "type": "subHeader", "content": "Copie a sua query SQL final e comentada para o arquivo transform.sql. No README.md, escreva um resumo do seu trabalho, incluindo o link para o dataset, suas descobertas na EDA e a descrição das novas features criadas." },
      { "pillId": "d3_p25", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-03): build and document data engineering pipeline for e-commerce reviews\ndocs(day-03): add EDA findings and feature engineering rationale\"\ngit push origin main" },
      { "pillId": "d3_p26", "title": "Fim da Transmissão do Dia 3", "type": "finalAssessment", "content": "Operador, hoje você agiu como um verdadeiro engenheiro de dados. Você não apenas transformou, mas primeiro investigou. Você não apenas escreveu código, mas o documentou. Esta tabela dourada não é apenas um conjunto de linhas; é um produto de engenharia, a fundação sobre a qual os seus modelos preditivos serão construídos. No Dia 6, usaremos este ativo para treinar um classificador com AutoML. Mas antes disso, amanhã, vamos explorar uma forma diferente de dar poder à IA: não através de treino, mas através de contexto. Vamos mergulhar no mundo do RAG. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-04",
    "dayNumber": 4,
    "title": "O Poder do Contexto",
    "subtitle": "Arquitetando o Especialista Cirúrgico",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d4_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Um LLM genérico é um exército. RAG (Retrieval-Augmented Generation) não altera o soldado; dá-lhe acesso instantâneo aos mapas do campo de batalha. Hoje, você não usa uma ferramenta mágica. Você constrói o sistema de inteligência que alimenta o seu exército, peça por peça." },
      { "pillId": "d4_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Projetar e implementar um pipeline RAG de nível de engenharia que ingere documentos privados, os converte em embeddings, os armazena num banco de dados vetorial e usa esse conhecimento para responder a perguntas de forma factual e rastreável." },
      { "pillId": "d4_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Vertex AI (Model Garden para Embedding, Vector Search)" },
      { "pillId": "d4_p04", "title": "", "type": "listItem", "content": "Google Cloud Storage" },
      { "pillId": "d4_p05", "title": "", "type": "listItem", "content": "Cloud Functions" },
      { "pillId": "d4_p06", "title": "", "type": "listItem", "content": "Python (google-cloud-aiplatform SDK)" },
      { "pillId": "d4_p07", "title": "Bloco 1: Setup da Arquitetura RAG", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d4_p08", "title": "Aquisição e Preparação das Fontes", "type": "subHeader", "content": "Colete os 3 documentos (Alphabet 10-K, anúncio do Gemini 1.5, carta aos acionistas) e organize-os numa pasta local." },
      { "pillId": "d4_p09", "title": "Configurar o Armazenamento de Documentos (GCS)", "type": "subHeader", "content": "No Console do Google Cloud, navegue para Cloud Storage. Crie um novo Bucket com um nome único global (ex: ia-bootcamp-rag-sources-SEU_NOME). Faça o upload dos seus 3 arquivos PDF para este bucket." },
      { "pillId": "d4_p10", "title": "Configurar o Banco de Dados Vetorial (Vertex AI Vector Search)", "type": "subHeader", "content": "Navegue para Vertex AI > Vector Search. Clique em 'Criar Índice'. Nome: rag_google_strategy_index, Dimensões: 768, Distância: Cosseno. Após a criação, crie um 'Ponto de Extremidade de Índice' e associe seu índice a ele." },
      { "pillId": "d4_p11", "title": "Pílula de Conhecimento", "type": "knowledgePill", "content": "O Índice é a base de dados que contém os seus vetores. O Ponto de Extremidade é a API pública que você usa para consultar esse índice. Você precisa de ambos." },
      { "pillId": "d4_p12", "title": "Bloco 2: O Pipeline de Indexação", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d4_p13", "title": "Instale as Bibliotecas", "type": "code", "language": "bash", "content": "pip install google-cloud-aiplatform google-cloud-storage PyPDF2" },
      { "pillId": "d4_p14", "title": "Código de Indexação (indexer.py)", "type": "code", "language": "python", "content": "import os\nfrom google.cloud import aiplatform, storage\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import PyPDFLoader\nimport time\n\n# --- CONFIGURAÇÃO (Altere com os seus valores) ---\nPROJECT_ID = \"ia-bootcamp-ops\"\nLOCATION = \"us-central1\"\nGCS_BUCKET_NAME = \"ia-bootcamp-rag-sources-SEU_NOME\" # Use o nome do seu bucket\nVECTOR_SEARCH_INDEX_ID = \"ID_DO_SEU_INDICE_AQUI\" # Copie do console do Vertex AI\n\n# --- INICIALIZAÇÃO DOS CLIENTES ---\naiplatform.init(project=PROJECT_ID, location=LOCATION)\nstorage_client = storage.Client(project=PROJECT_ID)\n\n# --- 1. CARREGAMENTO E DIVISÃO (CHUNKING) ---\nprint(\"Iniciando carregamento e chunking dos documentos...\")\ndocuments = []\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n\nbucket = storage_client.bucket(GCS_BUCKET_NAME)\nfor blob in bucket.list_blobs():\n    if blob.name.endswith(\".pdf\"):\n        temp_pdf_path = f\"/tmp/{blob.name}\"\n        blob.download_to_filename(temp_pdf_path)\n        \n        print(f\"Processando: {blob.name}\")\n        loader = PyPDFLoader(temp_pdf_path)\n        docs = loader.load_and_split(text_splitter)\n        documents.extend(docs)\n        os.remove(temp_pdf_path)\n\nprint(f\"Total de chunks criados: {len(documents)}\")\n\n# --- 2. GERAÇÃO DE EMBEDDINGS ---\nprint(\"Gerando embeddings com o modelo 'text-embedding-004'...\")\nmodel = aiplatform.TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n\nembeddings = []\nbatch_size = 5 \nfor i in range(0, len(documents), batch_size):\n    batch = [doc.page_content for doc in documents[i:i+batch_size]]\n    embeddings_batch = model.get_embeddings([{\"content\": text} for text in batch])\n    embeddings.extend([item.values for item in embeddings_batch])\n    print(f\"Lote {i//batch_size + 1} processado.\")\n    time.sleep(1) # Evitar atingir limites de quota da API\n    \nprint(f\"Total de embeddings gerados: {len(embeddings)}\")\n\n# --- 3. INSERÇÃO NO VECTOR SEARCH ---\nprint(\"Inserindo dados no Vertex AI Vector Search...\")\nupsert_data = []\nfor i, doc in enumerate(documents):\n    upsert_data.append({\n        \"id\": f\"doc_{i}\",\n        \"embedding\": embeddings[i],\n        \"restricts\": [\n            {\"namespace\": \"source\", \"allow\": [doc.metadata.get(\"source\", \"unknown\")]}\n        ]\n    })\n\nwith open(\"upsert_data.jsonl\", \"w\") as f:\n    for item in upsert_data:\n        f.write(f'{item}\\n')\n\nvector_search_index = aiplatform.MatchingEngineIndex(index_name=VECTOR_SEARCH_INDEX_ID)\nvector_search_index.upsert_datapoints(datapoints_jsonl_uri=\"upsert_data.jsonl\")\n\nprint(\"Pipeline de indexação concluído com sucesso!\")" },
      { "pillId": "d4_p15", "title": "Bloco 3: Construção do 'Interrogador'", "type": "sectionHeader", "content": "Duração: 3.5 Horas" },
      { "pillId": "d4_p16", "title": "Código do Interrogador (Cloud Function)", "type": "code", "language": "python", "content": "import functions_framework\nfrom google.cloud import aiplatform\n\n# --- CONFIGURAÇÃO ---\nPROJECT_ID = \"ia-bootcamp-ops\"\nLOCATION = \"us-central1\"\nVECTOR_SEARCH_ENDPOINT_ID = \"ID_DO_SEU_ENDPOINT_AQUI\"\nDEPLOYED_INDEX_ID = \"ID_DO_SEU_INDICE_NO_ENDPOINT_AQUI\"\n\n# --- INICIALIZAÇÃO ---\naiplatform.init(project=PROJECT_ID, location=LOCATION)\nembedding_model = aiplatform.TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\nllm = aiplatform.GenerativeModel(\"gemini-1.0-pro\")\n\n@functions_framework.http\ndef rag_interrogator(request):\n    request_json = request.get_json(silent=True)\n    query = request_json.get(\"query\", \"What is the strategy for AI?\")\n    \n    # 1. Converter a pergunta do utilizador em um vetor (embedding)\n    query_embedding = embedding_model.get_embeddings([{\"content\": query}])[0].values\n    \n    # 2. Pesquisar no Vector Search por vizinhos mais próximos\n    endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=VECTOR_SEARCH_ENDPOINT_ID)\n    \n    neighbors = endpoint.find_neighbors(\n        deployed_index_id=DEPLOYED_INDEX_ID,\n        queries=[query_embedding],\n        num_neighbors=5\n    )\n    \n    context = \" \".join([neighbor.datapoint.restricts[0]['allow'][0] for neighbor in neighbors[0]])\n    context = \"Contexto recuperado dos documentos: \" + context.replace('/tmp/', '') \n\n    # 3. Construir o Prompt para o LLM\n    final_prompt = f\"\"\"\n    Você é um assistente especialista que responde a perguntas baseando-se estritamente no contexto fornecido.\n    Se a resposta não estiver no contexto, diga \"A informação não está disponível nas minhas fontes.\"\n\n    Contexto: {context}\n\n    Pergunta: {query}\n\n    Resposta:\n    \"\"\"\n    \n    # 4. Chamar o LLM com o contexto\n    response = llm.generate_content(final_prompt)\n    \n    return {\n        \"response\": response.text,\n        \"context_used\": context\n    }", "validationCriteria": { "prompt": "Teste sua função com a query 'Qual a receita do Google Cloud em 2023?' e cole o campo 'context_used' da resposta JSON aqui:", "type": "string_contains_all", "values": ["Contexto recuperado", ".pdf"] } },
      { "pillId": "d4_p17", "title": "Bloco 4: Análise Crítica e Documentação", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d4_p18", "title": "Documentação (README.md)", "type": "code", "language": "markdown", "content": "# Arquitetura RAG Implementada\n\n[PDFs] -> [GCS] -> [Python Script (indexer.py)] -> Chunking/Embedding -> [Vertex AI Vector Search] -> [Cloud Function (interrogator)] <- [Pergunta do Utilizador]\n\n- **GCS:** Repositório de conhecimento bruto.\n- **Vector Search:** Banco de dados vetorial para busca de similaridade semântica.\n- **Cloud Function:** Orquestrador que converte a pergunta, busca o contexto e gera a resposta final.\n\n# Análise de Respostas\n\n(Inclua 2-3 exemplos de perguntas e as respostas geradas pela sua API, mostrando a rastreabilidade do contexto).\n\n# Desafios de Engenharia\n\n(Discuta as decisões que você tomou: Por que chunk_size=1000? Qual a importância da dimensão do embedding (768)? O que aconteceria se a dimensão estivesse errada?)" },
      { "pillId": "d4_p19", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-04): build and document a full RAG engineering pipeline\"\ngit push origin main" },
      { "pillId": "d4_p20", "title": "Fim da Transmissão do Dia 4", "type": "finalAssessment", "content": "Operador, você não usou RAG. Você o construiu. Você manipulou chunks, embeddings e bancos de dados vetoriais. Você orquestrou um pipeline que transforma conhecimento bruto em respostas inteligentes e rastreáveis. A caixa preta foi aberta. Amanhã, a missão muda drasticamente. Vamos para o cenário onde o contexto não é suficiente. Vamos realizar a cirurgia. Vamos ao fine-tuning. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-05",
    "dayNumber": 5,
    "title": "A Cirurgia Neural",
    "subtitle": "Modificando o Comportamento na Fonte",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d5_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "No Dia 4, você deu um livro a um soldado (RAG). Hoje, você o envia para a escola de forças especiais. O fine-tuning não é sobre dar mais conhecimento; é sobre reconfigurar os seus reflexos, a sua intuição, o seu estilo. Quando a mudança de comportamento necessária é tão fundamental que nenhum prompt consegue ensiná-la, você abre o capô e religa os circuitos. Hoje, você é um neurocirurgião de IA." },
      { "pillId": "d5_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Executar uma operação de fine-tuning de ponta a ponta: pegar um modelo de código aberto, criar um dataset de treino especializado, re-treiná-lo em uma tarefa de nicho na Vertex AI, e avaliar rigorosamente o seu desempenho para provar a sua nova habilidade." },
      { "pillId": "d5_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Hugging Face Hub" },
      { "pillId": "d5_p04", "title": "", "type": "listItem", "content": "Bibliotecas: transformers, datasets, evaluate, scikit-learn" },
      { "pillId": "d5_p05", "title": "", "type": "listItem", "content": "Vertex AI Workbench, GCS, Python" },
      { "pillId": "d5_p06", "title": "Bloco 1: Preparação Pré-Operatória", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d5_p07", "title": "Preparação do Ambiente (Vertex AI Workbench)", "type": "subHeader", "content": "Crie um notebook gerenciado na Vertex AI Workbench: Nome: workbench-fine-tuning-ops, Ambiente: Python 3, Máquina: e2-standard-4." },
      { "pillId": "d5_p08", "title": "Instalação do Kit Cirúrgico", "type": "code", "language": "python", "content": "%pip install --upgrade pip\n%pip install \"transformers[torch]\" datasets accelerate evaluate scikit-learn --upgrade" },
      { "pillId": "d5_p09", "title": "Pílula de Conhecimento", "type": "knowledgePill", "content": "O %pip é um 'comando mágico' do Jupyter que garante que as bibliotecas sejam instaladas no kernel correto do notebook." },
      { "pillId": "d5_p10", "title": "Forja do Dataset", "type": "code", "language": "python", "content": "import json\nimport pandas as pd\n\n# Definição da tarefa: Classificar o tom de uma review de produto.\ndata = [\n    {\"texto\": \"Este produto é funcional, mas a embalagem chegou danificada e o manual é confuso...\", \"label\": \"Crítico\"},\n    {\"texto\": \"HAHAHA, comprei isso de piada para o meu amigo e a reação dele valeu cada centavo!...\", \"label\": \"Humorístico\"},\n    {\"texto\": \"A bateria dura exatamente 12 horas e 15 minutos... A construção é de plástico ABS.\", \"label\": \"Informativo\"},\n    {\"texto\": \"Simplesmente o melhor investimento que fiz este ano. Mudou completamente a minha rotina...\", \"label\": \"Entusiasmado\"},\n    {\"texto\": \"Não funcionou. Veio quebrado. Pedi reembolso. Péssima experiência.\", \"label\": \"Crítico\"},\n    {\"texto\": \"O guia de instalação foi passo a passo, super detalhado. Consegui montar em 20 minutos...\", \"label\": \"Informativo\"},\n    {\"texto\": \"Chegou antes do prazo, bem embalado. A cor é um pouco diferente da foto, mas gostei...\", \"label\": \"Informativo\"},\n    {\"texto\": \"Usei para pregar uma peça no meu chefe e quase fui demitido. 10/10, faria de novo.\", \"label\": \"Humorístico\"},\n    {\"texto\": \"Totalmente decepcionante. As promessas do marketing são pura ficção...\", \"label\": \"Crítico\"},\n    {\"texto\": \"Estou apaixonada! O design é elegante e a funcionalidade supera todas as expectativas.\", \"label\": \"Entusiasmado\"}\n]\n\n# Duplicar os dados para um volume mínimo de treino\nfull_data = pd.DataFrame(data * 25)\n\n# Salvar o arquivo localmente no ambiente do notebook\ndataset_path = \"dataset_tom_review.jsonl\"\nfull_data.to_json(dataset_path, orient='records', lines=True, force_ascii=False)\n\nprint(f\"Dataset com {len(full_data)} exemplos criado em '{dataset_path}'\")" },
      { "pillId": "d5_p11", "title": "Bloco 2: A Cirurgia Neural (Treino)", "type": "sectionHeader", "content": "Duração: 3 Horas" },
      { "pillId": "d5_p12", "title": "Carregar Modelo e Definir Argumentos de Treino", "type": "code", "language": "python", "content": "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n# Carregar o modelo base, já informando sobre as novas \"habilidades\" que ele aprenderá.\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME, \n    num_labels=num_labels,\n    id2label=id2label,\n    label2id=label2id\n)\n\n# Definir os parâmetros da \"cirurgia\"\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    logging_steps=10,\n    report_to=\"none\"\n)" },
      { "pillId": "d5_p13", "title": "Bloco 3: Relatório Pós-Operatório (Avaliação)", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d5_p14", "title": "Cálculo das Métricas de Avaliação", "type": "code", "language": "python", "content": "import numpy as np\nimport evaluate\n\n# Carregar a métrica de acurácia\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n# Precisamos de um novo Trainer para usar a função compute_metrics\neval_trainer = Trainer(\n    model=model, # O modelo já foi treinado!\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer\n)\n\n# Executar a avaliação no conjunto de teste\neval_results = eval_trainer.evaluate()\n\nprint(\"--- Resultados da Avaliação ---\")\nprint(eval_results)", "validationCriteria": { "prompt": "Após a avaliação, cole o valor numérico da sua 'eval_accuracy' (ex: 0.98):", "type": "is_number_between", "min": 0.7, "max": 1 } },
      { "pillId": "d5_p15", "title": "Análise Detalhada com Matriz de Confusão", "type": "code", "language": "python", "content": "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Obter as previsões no conjunto de teste\npredictions = eval_trainer.predict(tokenized_dataset[\"test\"])\npred_labels = np.argmax(predictions.predictions, axis=-1)\n\n# Criar a matriz de confusão\ncm = confusion_matrix(tokenized_dataset[\"test\"][\"labels\"], pred_labels)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_list)\n\n# Plotar a matriz\nfig, ax = plt.subplots(figsize=(8, 8))\ndisp.plot(ax=ax, cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confusão Pós-Fine-Tuning\")\nplt.show()" },
      { "pillId": "d5_p16", "title": "Teste em um Exemplo Real", "type": "code", "language": "python", "content": "from transformers import pipeline\n\n# Usar a abstração \"pipeline\" para testar facilmente\nmeu_classificador = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n\ntexto_exemplo = \"O produto demorou a chegar e veio com um arranhão na lateral. Funciona, mas estou desapontado com o controle de qualidade.\"\nresultado = meu_classificador(texto_exemplo)\n\nprint(f\"Texto: '{texto_exemplo}'\")\nprint(f\"Previsão: {resultado}\")" },
      { "pillId": "d5_p17", "title": "Bloco 4: Documentação e Consolidação", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d5_p18", "title": "Documentação (README.md)", "type": "code", "language": "markdown", "content": "# Missão e Modelo Base\n\n(Descrição da missão e do modelo base utilizado).\n\n# Tarefa de Especialização\n\n(Descrição da tarefa de classificação de tom).\n\n# Resultados da Avaliação\n\n- **Acurácia no Conjunto de Teste:** Apresente o resultado de `eval_results`.\n- **Matriz de Confusão:**\n  ![Matriz de Confusão](confusion_matrix.png)\n- **Análise da Matriz:** Explique o que a matriz mostra. 'O modelo demonstrou um desempenho excelente, com a maioria dos erros ocorrendo entre as classes X e Y...'\n- **Exemplo de Inferência:** Cole o resultado do teste no exemplo real." },
      { "pillId": "d5_p19", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-05): fine-tune and evaluate a sentiment classifier on Vertex AI\"\ngit push origin main" },
      { "pillId": "d5_p20", "title": "Fim da Transmissão do Dia 5", "type": "finalAssessment", "content": "Operador, hoje você não apenas realizou a cirurgia; você fez os exames pós-operatórios. Você provou, com dados e métricas, que a sua intervenção foi bem-sucedida. Este ciclo completo – treinar E avaliar – é o que define um profissional. Mas esta foi a abordagem manual. Amanhã, vamos contrastar esta cirurgia artesanal com a automação industrial. Vamos explorar o AutoML e ver como a máquina pode, por vezes, superar o mestre. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-06",
    "dayNumber": 6,
    "title": "A Linha de Montagem da Inteligência",
    "subtitle": "ML Automatizado",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d6_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "No Dia 5, você foi um artesão. Hoje, você é o diretor da fábrica. O seu objetivo não é construir um carro à mão, mas projetar a linha de montagem que testa milhares de designs para encontrar o mais eficiente. AutoML não é \"IA para preguiçosos\"; é alavancagem estratégica. É usar a IA para construir IA, permitindo-lhe focar no problema de negócio." },
      { "pillId": "d6_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Utilizar a \"Tabela Dourada\" para treinar, avaliar, implantar e testar um modelo de classificação de alta performance com Vertex AI AutoML. A missão principal é extrair a lógica interna do modelo (feature importance) e traduzir esses insights técnicos em inteligência de negócio acionável." },
      { "pillId": "d6_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Vertex AI (Datasets, AutoML Tabular, Endpoints)" },
      { "pillId": "d6_p04", "title": "", "type": "listItem", "content": "BigQuery" },
      { "pillId": "d6_p05", "title": "", "type": "listItem", "content": "Cloud Shell" },
      { "pillId": "d6_p06", "title": "Bloco 1: Preparação do 'Chassis'", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d6_p07", "title": "Query para a View de Treino", "type": "code", "language": "sql", "content": "-- Esta query seleciona apenas as colunas úteis da nossa tabela dourada\n-- para criar uma 'view' limpa e pronta para o treino do AutoML.\nSELECT\n  -- Features (as \"pistas\" para o modelo):\n  texto_review,\n  tem_titulo,\n  tamanho_review,\n  contagem_feedback_positivo,\n  e_recomendado,\n  divisao,\n  departamento,\n  classe,\n  media_rating_departamento,\n\n  -- Alvo (o que queremos prever):\n  sentimento\nFROM\n  `ia-bootcamp-ops.bootcamp_ecommerce.reviews_golden_table`\nWHERE \n  -- Garantimos que o nosso alvo não seja nulo.\n  sentimento IS NOT NULL;" },
      { "pillId": "d6_p08", "title": "Pílula de Conhecimento", "type": "knowledgePill", "content": "Por que remover id_produto ou idade? id_produto é um identificador aleatório sem poder preditivo. idade poderia ser usada, mas para este problema, a sua influência pode ser ruído. Remover colunas irrelevantes acelera o treino e pode melhorar a performance do modelo, forçando-o a focar nos sinais mais fortes." },
      { "pillId": "d6_p09", "title": "Salvar como View", "type": "subHeader", "content": "Clique em 'Salvar' -> 'Salvar View'. Selecione seu dataset bootcamp_ecommerce. Nome da View: v_reviews_training_dataset." },
      { "pillId": "d6_p10", "title": "Bloco 2: Lançamento da Linha de Montagem", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d6_p11", "title": "Crie o Dataset no Vertex AI", "type": "subHeader", "content": "Navegue para Vertex AI -> Datasets. + Create. Nome: ecommerce_sentiment_dataset, Tipo: Tabular, Objetivo: Classification. Fonte: Selecione a sua view v_reviews_training_dataset do BigQuery." },
      { "pillId": "d6_p12", "title": "Inicie o Treino AutoML", "type": "subHeader", "content": "Clique em 'Treinar Novo Modelo'. Método: AutoML. Coluna Alvo: sentimento. Nome do Modelo: automl_sentiment_classifier_v1. Orçamento de Treino: 1 hora de nó. Clique em 'Iniciar Treino'." },
      { "pillId": "d6_p13", "title": "Bloco 3: Análise e Teste do Produto Final", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d6_p14", "title": "Análise do Relatório de Avaliação", "type": "subHeader", "content": "Vá para Vertex AI -> Models e clique no seu modelo. Explore a aba 'Avaliar'. Analise a Matriz de Confusão e a Importância do Recurso (Feature Importance)." },
      { "pillId": "d6_p15", "title": "Tradução para Insights de Negócio", "type": "subHeader", "content": "Faça o exercício de tradução: Observação Técnica (tamanho_review é importante) -> Insight de Negócio (incentivar reviews mais longas)." },
      { "pillId": "d6_p16", "title": "Implantação do Modelo (Deploy)", "type": "subHeader", "content": "Na página do seu modelo, vá para a aba 'Implantar e Testar'. Clique em 'Implantar no Endpoint'. Nome: sentiment_classifier_endpoint. Tipo de Máquina: n1-standard-2." },
      { "pillId": "d6_p17", "title": "Teste de Inferência", "type": "code", "language": "python", "content": "import google.cloud.aiplatform as aiplatform\n\nPROJECT_ID = \"ia-bootcamp-ops\"\nENDPOINT_ID = \"SEU_ENDPOINT_ID_AQUI\"\nLOCATION = \"us-central1\"\n\naiplatform.init(project=PROJECT_ID, location=LOCATION)\n\ninstance = {\n    \"texto_review\": \"The package arrived late but the product works perfectly.\",\n    \"tem_titulo\": False,\n    \"tamanho_review\": 60,\n    \"contagem_feedback_positivo\": 10,\n    \"e_recomendado\": True,\n    \"divisao\": \"General\",\n    \"departamento\": \"Tops\",\n    \"classe\": \"Blouses\",\n    \"media_rating_departamento\": 4.1\n}\n\nendpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}\")\nprediction = endpoint.predict(instances=[instance])\n\nprint(prediction)", "validationCriteria": { "prompt": "Execute o script de teste e cole a classe prevista (o valor de 'displayNames') aqui:", "type": "string_contains_any", "values": ["Positivo", "Negativo", "Neutro"] } },
      { "pillId": "d6_p18", "title": "Bloco 4: Documentação e Arquivamento", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d6_p19", "title": "Ação Crítica (Controle de Custos)", "type": "note", "content": "Navegue de volta para Vertex AI -> Endpoints. Clique nos três pontos ao lado do seu sentiment_classifier_endpoint e selecione 'Cancelar implantação do modelo' (Undeploy model). Isto desliga a máquina virtual que hospeda o seu modelo, interrompendo os custos." },
      { "pillId": "d6_p20", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-06): train, evaluate, and deploy AutoML classification model\"\ngit push origin main" },
      { "pillId": "d6_p21", "title": "Fim da Transmissão do Dia 6", "type": "finalAssessment", "content": "Operador, hoje você delegou com precisão. Você preparou a matéria-prima, projetou o 'chassis' com uma VIEW, supervisionou a linha de montagem, analisou o produto final, e até mesmo o testou na estrada com uma chamada de API. Você concluiu o ciclo de vida completo de um projeto de AutoML. Agora, o seu arsenal está a crescer. Mas modelos, sejam artesanais ou industrializados, têm pontos cegos. Como podemos confiar neles? Amanhã, a fase de construção termina e a fase de interrogatório começa. Vamos colocar os nossos modelos sob um microscópio para encontrar as suas fraquezas. Prepare-se para o 'Red Teaming'. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-07",
    "dayNumber": 7,
    "title": "A Sala do Espelho",
    "subtitle": "Ataque, Avaliação e Iteração ('Red Team')",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d7_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Um engenheiro ingênuo celebra quando o modelo funciona. Um engenheiro de elite obceca-se em descobrir onde ele falha. Construir um modelo é uma hipótese; testá-lo é ciência. Hoje, você é o adversário. O seu trabalho é ser o 'Red Team': uma equipe dedicada a quebrar o sistema para o tornar mais forte." },
      { "pillId": "d7_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Avaliar e comparar programaticamente o modelo fine-tuned (Dia 5) e o modelo AutoML (Dia 6) numa matriz de ataque qualitativa. O resultado será um 'Model Card' para cada um e um plano de ação claro para a v2." },
      { "pillId": "d7_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Modelos dos Dias 5 e 6" },
      { "pillId": "d7_p04", "title": "", "type": "listItem", "content": "Vertex AI Workbench, Vertex AI Endpoints" },
      { "pillId": "d7_p05", "title": "", "type": "listItem", "content": "Google Sheets/CSV, Python" },
      { "pillId": "d7_p06", "title": "Bloco 1: Preparação do Campo de Batalha", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d7_p07", "title": "Criação da Matriz de Ataque", "type": "subHeader", "content": "Crie um arquivo matriz_de_ataque.csv com as colunas: id_teste,categoria_teste,texto_input,label_esperada. Preencha com 20-30 casos de teste desafiadores (Sarcasmo, Negação, Ambiguidade, etc.)." },
      { "pillId": "d7_p08", "title": "Reativação da Infraestrutura", "type": "subHeader", "content": "Reative o endpoint do modelo AutoML do Dia 6 se você o desligou." },
      { "pillId": "d7_p09", "title": "Bloco 2: Execução Programática do Ataque", "type": "sectionHeader", "content": "Duração: 4 Horas" },
      { "pillId": "d7_p10", "title": "Setup do Notebook de Avaliação", "type": "code", "language": "python", "content": "%pip install pandas \"transformers[torch]\" google-cloud-aiplatform --upgrade" },
      { "pillId": "d7_p11", "title": "Carregamento dos Modelos e Dados", "type": "code", "language": "python", "content": "import pandas as pd\nfrom transformers import pipeline\nimport google.cloud.aiplatform as aiplatform\n\n# --- CONFIGURAÇÃO ---\nGCP_PROJECT_ID = \"ia-bootcamp-ops\"\nGCP_LOCATION = \"us-central1\"\nAUTOML_ENDPOINT_ID = \"SEU_ENDPOINT_ID_AQUI\"\nFINETUNE_MODEL_PATH = \"../dia-05-fine-tuning-cirurgiao/MODELO_SALVO\"\n\n# --- CARREGAR OS MODELOS ---\nclassifier_finetune = pipeline(\"text-classification\", model=FINETUNE_MODEL_PATH)\naiplatform.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)\nautoml_endpoint = aiplatform.Endpoint(endpoint_name=AUTOML_ENDPOINT_ID)\n\n# Carregar a matriz de ataque\ndf_attack = pd.read_csv(\"matriz_de_ataque.csv\")" },
      { "pillId": "d7_p12", "title": "Loop de Avaliação Automatizada", "type": "code", "language": "python", "content": "results = []\n\nfor index, row in df_attack.iterrows():\n    text = row['texto_input']\n    \n    # 1. Previsão do Modelo Fine-Tuned\n    pred_finetune = classifier_finetune(text)[0]['label']\n\n    # 2. Previsão do Modelo AutoML\n    instance = {\"texto_review\": text}\n    prediction = automl_endpoint.predict(instances=[instance])\n    pred_automl = prediction.predictions[0]['displayNames'][0]\n\n    results.append({\n        'id_teste': row['id_teste'],\n        'categoria_teste': row['categoria_teste'],\n        'texto_input': text,\n        'label_esperada': row['label_esperada'],\n        'predicao_finetune': pred_finetune,\n        'predicao_automl': pred_automl\n    })\n\ndf_results = pd.DataFrame(results)\ndf_results.to_csv(\"relatorio_red_team.csv\", index=False)\n\ndisplay(df_results)" },
      { "pillId": "d7_p13", "title": "Bloco 3: Análise dos Padrões de Falha", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d7_p14", "title": "Análise Conceitual", "type": "paragraph", "content": "Abra o relatorio_red_team.csv. Crie colunas de análise para identificar falhas (label_esperada vs. predição). Filtre por categoria de teste e procure padrões: Onde um modelo é mais forte que o outro? Onde ambos falham? Formule hipóteses para esses comportamentos.", "validationCriteria": { "prompt": "Após analisar seu 'relatorio_red_team.csv', escreva uma frase resumindo a principal fraqueza que você encontrou em um dos modelos:", "type": "string_contains_any", "values": ["sarcasmo", "robusto", "ambiguidade", "falha", "negação"] } },
      { "pillId": "d7_p15", "title": "Bloco 4: Documentação e Plano de Ação (Model Cards)", "type": "sectionHeader", "content": "Duração: 2 Horas" },
      { "pillId": "d7_p16", "title": "Model Cards (README.md)", "type": "code", "language": "markdown", "content": "# Red Teaming e Análise Comparativa\n\n## Model Card: DistilBERT Fine-tuned (Artesão)\n- **Arquitetura:** `distilbert-base-uncased`\n- **Performance Quantitativa:** Acurácia de X%.\n- **Forças:** [Ex: Excelente em sarcasmo]\n- **Fraquezas:** [Ex: Sensível a erros ortográficos]\n- **Uso Recomendado:** Cenários que exigem compreensão de nuances linguísticas específicas.\n\n---\n\n## Model Card: Vertex AI AutoML (Linha de Montagem)\n- **Arquitetura:** Ensemble de modelos.\n- **Performance Quantitativa:** Acurácia de Y%.\n- **Forças:** [Ex: Robusto a erros ortográficos]\n- **Fraquezas:** [Ex: Falha em detectar sarcasmo sutil]\n- **Uso Recomendado:** Classificador geral de alta performance.\n\n---\n\n## Plano de Ação para a Versão 2\n- **Enriquecimento do Dataset:** Adicionar mais exemplos de [sarcasmo, negação] ao dataset de treino.\n- **Iteração do Fine-tuning:** Re-treinar o modelo com o dataset enriquecido.\n- **Combinação (Ensembling):** Usar o AutoML como modelo principal e o fine-tuned como segunda verificação para casos específicos." },
      { "pillId": "d7_p17", "title": "Ação Crítica (Controle de Custos)", "type": "note", "content": "Cancele a implantação (Undeploy) do seu endpoint AutoML para parar os custos." },
      { "pillId": "d7_p18", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-07): perform programmatic red team evaluation of models\"\ngit push origin main" },
      { "pillId": "d7_p19", "title": "Fim da Transmissão do Dia 7", "type": "finalAssessment", "content": "Operador, hoje você transcendeu a construção. Você adotou a mentalidade do adversário para fortalecer as suas criações. Você aprendeu que nenhum modelo é perfeito e que a verdadeira engenharia de ML reside no ciclo contínuo de construir, atacar, analisar e iterar. O plano de ação que você criou não é o fim de um projeto; é o início do próximo. Agora que você sabe como treinar, avaliar e fortalecer modelos, como você transforma este processo, que ainda tem passos manuais, num sistema de produção automatizado e repetível? Amanhã, vamos entrar no domínio do MLOps. Vamos construir um pipeline que leva o seu código de treino e o transforma numa linha de montagem de modelos. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-08",
    "dayNumber": 8,
    "title": "A Fábrica de IA",
    "subtitle": "Orquestração e MLOps com Vertex AI Pipelines",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d8_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Um modelo treinado no seu notebook é um protótipo. Um modelo que pode ser retreinado, avaliado e registado automaticamente é um produto. Hoje, você para de executar scripts e começa a orquestrar sistemas. O pipeline é o seu verdadeiro entregável; o modelo é apenas o seu artefato." },
      { "pillId": "d8_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Orquestrar o processo de fine-tuning do nosso modelo de sentimento (Dia 5) num pipeline automatizado que ingere dados, treina um modelo e o regista no Vertex AI Model Registry, criando um fluxo de trabalho de MLOps de ponta a ponta." },
      { "pillId": "d8_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "Vertex AI Pipelines, KFP SDK" },
      { "pillId": "d8_p04", "title": "", "type": "listItem", "content": "Vertex AI Model Registry" },
      { "pillId": "d8_p05", "title": "", "type": "listItem", "content": "Google Cloud Build, Docker, Artifact Registry" },
      { "pillId": "d8_p06", "title": "Bloco 1: Engenharia do Componente de Treino", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d8_p07", "title": "O Script de Treino (train.py)", "type": "code", "language": "python", "content": "import argparse\nfrom google.cloud import aiplatform\n\n# 1. SETUP DO PARSER DE ARGUMENTOS\nparser = argparse.ArgumentParser()\nparser.add_argument('--project_id', type=str, required=True)\nparser.add_argument('--location', type=str, required=True)\nparser.add_argument('--model_display_name', type=str, required=True)\nparser.add_argument('--bucket_uri', type=str, required=True)\nargs = parser.parse_args()\n\n# 2. LÓGICA DE TREINO (adaptada do Dia 5)\n# ... (Código de treino simulado para focar no pipeline)\nprint(\"Simulando treino do modelo...\")\noutput_dir = \"./modelo-treinado\"\n\nprint(\"Treino concluído. Registando o modelo no Vertex AI...\")\n\n# 3. REGISTO DO MODELO\naiplatform.init(project=args.project_id, location=args.location)\n\nmodel = aiplatform.Model.upload(\n    display_name=args.model_display_name,\n    artifact_uri=output_dir,\n    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.1-12:latest\",\n    description=\"Modelo de sentimento treinado via pipeline MLOps.\"\n)\n\nprint(f\"Modelo registado com sucesso! Nome: {model.resource_name}\")" },
      { "pillId": "d8_p08", "title": "O Dockerfile", "type": "code", "language": "dockerfile", "content": "FROM python:3.9-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\n" },
      { "pillId": "d8_p09", "title": "requirements.txt", "type": "code", "language": "text", "content": "pandas\npyarrow\ndb-dtypes\ntransformers\ndatasets\naccelerate\n\"torch~=1.12.0\"\ngoogle-cloud-aiplatform\ngcsfs" },
      { "pillId": "d8_p10", "title": "Bloco 2: Construção Automatizada com Cloud Build", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d8_p11", "title": "Crie o Repositório no Artifact Registry", "type": "code", "language": "bash", "content": "gcloud artifacts repositories create bootcamp-repo --repository-format=docker --location=us-central1" },
      { "pillId": "d8_p12", "title": "Submeta o Build", "type": "code", "language": "bash", "content": "export PROJECT_ID=$(gcloud config get-value project)\nexport IMAGE_URI=\"us-central1-docker.pkg.dev/${PROJECT_ID}/bootcamp-repo/sentiment-trainer:v1\"\n\ngcloud builds submit dia-08-mlops-pipeline/training_component \\\n  --tag $IMAGE_URI" },
      { "pillId": "d8_p13", "title": "Pílula de Conhecimento", "type": "knowledgePill", "content": "O comando gcloud builds submit comprime a pasta, envia-a para o Cloud Build, que executa o Dockerfile num worker na nuvem, constrói a imagem Docker, e a envia para o seu Artifact Registry. Você não precisa do Docker instalado localmente." },
      { "pillId": "d8_p14", "title": "Bloco 3: Construção e Execução do Pipeline", "type": "sectionHeader", "content": "Duração: 3.5 Horas" },
      { "pillId": "d8_p15", "title": "Definição do Pipeline (KFP SDK)", "type": "code", "language": "python", "content": "from kfp import dsl\nfrom kfp.v2 import compiler\nfrom google.cloud import aiplatform\n\nPROJECT_ID = \"ia-bootcamp-ops\"\nREGION = \"us-central1\"\nBUCKET_NAME = \"ia-bootcamp-artefatos-unique-name\"\nPIPELINE_ROOT = f\"gs://{BUCKET_NAME}/pipeline-root\"\nIMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/bootcamp-repo/sentiment-trainer:v1\"\n\n@dsl.container_component\ndef train_and_register_model(project_id: str, location: str, model_display_name: str, bucket_uri: str):\n    return dsl.ContainerSpec(\n        image=IMAGE_URI,\n        command=[\"python\", \"train.py\"],\n        args=[\"--project_id\", project_id, \"--location\", location, \"--model_display_name\", model_display_name, \"--bucket_uri\", bucket_uri,],\n    )\n\n@dsl.pipeline(name=\"sentiment-training-pipeline\")\ndef sentiment_pipeline(project: str = PROJECT_ID, location: str = REGION, model_name: str = \"sentiment-classifier-pipeline\", bucket: str = BUCKET_NAME):\n    train_task = train_and_register_model(\n        project_id=project,\n        location=location,\n        model_display_name=model_name,\n        bucket_uri=f\"gs://{bucket}\"\n    )\n\ncompiler.Compiler().compile(pipeline_func=sentiment_pipeline, package_path=\"sentiment_pipeline.json\")\n\naiplatform.init(project=PROJECT_ID, location=REGION)\n\njob = aiplatform.PipelineJob(\n    display_name=\"sentiment-pipeline-run-01\",\n    template_path=\"sentiment_pipeline.json\",\n    pipeline_root=PIPELINE_ROOT,\n    parameter_values={\"model_name\": \"sentiment-v1-run01\"}\n)\n\njob.run()" },
      { "pillId": "d8_p16", "title": "Bloco 4: Verificação e Documentação", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d8_p17", "title": "Monitoramento e Verificação", "type": "subHeader", "content": "Vá para Vertex AI -> Pipelines para acompanhar a execução. Depois, vá para Vertex AI -> Model Registry para ver o seu novo modelo registrado.", "validationCriteria": { "prompt": "Vá ao Vertex AI Model Registry, clique no seu novo modelo e cole o 'Nome do recurso' completo aqui:", "type": "string_matches_pattern", "pattern": "projects/ia-bootcamp-ops/locations/us-central1/models/" } },
      { "pillId": "d8_p18", "title": "Documentação (README.md)", "type": "code", "language": "markdown", "content": "# Objetivo\nAutomatizar o treino e registo de um modelo de sentimento com um pipeline MLOps.\n\n# Arquitetura\n- **Cloud Build:** Automação da criação de imagens Docker.\n- **Vertex AI Pipeline:** Orquestração do componente de treino.\n- **Vertex AI Model Registry:** Destino final do artefato do pipeline.\n\n(Inclua um screenshot da sua execução bem-sucedida do pipeline no console).\n\n# Resultado\nO pipeline executou com sucesso e registou um novo modelo chamado 'sentiment-v1-run01' no Vertex AI Model Registry, pronto para ser implantado." },
      { "pillId": "d8_p19", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-08): build and run a Vertex AI MLOps pipeline with Cloud Build\"\ngit push origin main" },
      { "pillId": "d8_p20", "title": "Fim da Transmissão do Dia 8", "type": "finalAssessment", "content": "Operador, hoje você deu o salto de industrial para arquiteto de sistemas. O seu modelo não é mais algo que uma fábrica produz; é o produto de uma fábrica autogerida e automatizada. Você aprendeu a orquestrar sistemas complexos de forma robusta e reproduzível. Agora, com o ciclo de vida do modelo sob controlo, a próxima fronteira nos chama. Onde os modelos não são apenas ferramentas passivas que classificam dados, mas agentes ativos que raciocinam, planeiam e usam outras ferramentas para alcançar objetivos. Amanhã, vamos montar a equipe de assalto. Entraremos no mundo dos Agentes de IA. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-09",
    "dayNumber": 9,
    "title": "A Equipe de Assalto",
    "subtitle": "Arquitetura e Protótipo de Agentes de IA",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d9_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Um LLM é um especialista em linguagem. Um modelo de ML clássico é um especialista em padrões. Uma API é um especialista em dados. Individualmente, são poderosos. Coordenados, são uma força imparável. Um 'Agente' não é um modelo; é um sistema que combina um cérebro (LLM), ferramentas (outros modelos, APIs) e um ciclo de decisão. Hoje, você constrói o operador que as utiliza." },
      { "pillId": "d9_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Projetar e prototipar um Agente de IA funcional que decompõe um pedido complexo, seleciona a ferramenta certa e combina os resultados para fornecer uma resposta, usando o Gemini como cérebro e conectando-se a ferramentas reais." },
      { "pillId": "d9_p03", "title": "Arsenal Técnico", "type": "listItem", "content": "API do Gemini" },
      { "pillId": "d9_p04", "title": "", "type": "listItem", "content": "Python (requests, beautifulsoup4, re)" },
      { "pillId": "d9_p05", "title": "", "type": "listItem", "content": "Arquitetura de Agentes (padrão ReAct)" },
      { "pillId": "d9_p06", "title": "Bloco 1: Doutrina e Arquitetura do Agente", "type": "sectionHeader", "content": "Duração: 2 Horas" },
      { "pillId": "d9_p07", "title": "Estudo da Doutrina ReAct", "type": "subHeader", "content": "Compreender o padrão ReAct (Reason + Act) e desenhar a arquitetura do nosso agente antes de escrever código. O resultado é o seu diagrama de fluxo do 'Analista de Empresas Júnior'." },
      { "pillId": "d9_p08", "title": "Bloco 2: Construção do Arsenal de Ferramentas", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d9_p09", "title": "Código das Ferramentas (tools.py)", "type": "code", "language": "python", "content": "import requests\nfrom bs4 import BeautifulSoup\nimport re\n\n# Ferramenta 1: Busca na Web\ndef web_search_tool(query: str) -> str:\n    # ... (código do web scraper)\n    return \"Web search result for \" + query\n\n# Ferramenta 2: Analisador de Sentimento\ndef sentiment_analyzer_tool(text: str) -> str:\n    API_URL = \"URL_DA_SUA_API_DE_SENTIMENTO_AQUI\"\n    if \"URL_DA_SUA_API\" in API_URL:\n        print(\"AVISO: URL da API de sentimento não configurada. Usando simulação.\")\n        if any(kw in text.lower() for kw in [\"bom\", \"crescimento\", \"lucro\"]): return \"Sentimento: Positivo\"\n        if any(kw in text.lower() for kw in [\"ruim\", \"perda\", \"crise\"]): return \"Sentimento: Negativo\"\n        return \"Sentimento: Neutro\"\n    # ... (código de chamada da API)\n\n# Ferramenta 3: Preço da Ação\ndef stock_price_tool(ticker: str) -> str:\n    # ... (código da API do Financial Modeling Prep)\n    return f\"Preço da ação para {ticker}: $100.00\"" },
      { "pillId": "d9_p10", "title": "Bloco 3: Engenharia do Cérebro e Loop do Agente", "type": "sectionHeader", "content": "Duração: 3.5 Horas" },
      { "pillId": "d9_p11", "title": "Código do Agente (agent.py)", "type": "code", "language": "python", "content": "import google.generativeai as genai\nimport os\nimport re\nfrom tools import web_search_tool, sentiment_analyzer_tool, stock_price_tool\n\ngenai.configure(api_key=\"SUA_API_KEY_DO_GOOGLE_AI_STUDIO\")\n\nAVAILABLE_TOOLS = {\n    \"web_search\": web_search_tool,\n    \"sentiment_analyzer\": sentiment_analyzer_tool,\n    \"stock_price\": stock_price_tool,\n}\n\nPERSONA = \"Você é um agente de IA assistente...\"\nREACT_INSTRUCTIONS = \"Você deve decompor a tarefa...\"\nTOOL_DESCRIPTIONS = \"Ferramentas Disponíveis:...\"\nSYSTEM_PROMPT = \"\\n\".join([PERSONA, REACT_INSTRUCTIONS, TOOL_DESCRIPTIONS])\n\nmodel = genai.GenerativeModel('gemini-pro')\n\ndef run_agent(user_prompt: str):\n    print(f\"======= INICIANDO MISSÃO: {user_prompt} =======\")\n    conversation_history = [SYSTEM_PROMPT, f\"TAREFA: {user_prompt}\"]\n    \n    for i in range(5):\n        print(f\"\\n--- CICLO DE PENSAMENTO {i+1} ---\")\n        prompt_for_model = \"\\n\".join(conversation_history)\n        response = model.generate_content(prompt_for_model)\n        agent_output = response.text.strip()\n        print(f\"Saída do Agente:\\n{agent_output}\")\n        conversation_history.append(f\"Saída do Agente:\\n{agent_output}\")\n        \n        action_match = re.search(r\"Ação:\\s*(\\w+)\\((.*?)\\)\", agent_output, re.DOTALL)\n        \n        if not action_match:\n            print(\"======= MISSÃO CONCLUÍDA (Sem Ação válida encontrada) =======\")\n            break\n            \n        tool_name = action_match.group(1).strip()\n        tool_input = action_match.group(2).strip()\n\n        if tool_name == \"responder_ao_usuario\":\n            print(\"======= MISSÃO CONCLUÍDA (Resposta Final) =======\")\n            break\n\n        if tool_name in AVAILABLE_TOOLS:\n            tool_function = AVAILABLE_TOOLS[tool_name]\n            observation = tool_function(tool_input)\n            conversation_history.append(f\"Observação: {observation}\")\n        else:\n            conversation_history.append(f\"Observação: Erro, a ferramenta '{tool_name}' não existe.\")\n\nif __name__ == \"__main__\":\n    run_agent(\"Faça uma análise rápida da Microsoft (ticker MSFT).\")", "validationCriteria": { "prompt": "Execute seu agente com a tarefa sobre a Microsoft e cole a frase final gerada pela ação 'responder_ao_usuario':", "type": "string_contains_all", "values": ["Microsoft", "sentimento", "preço"] } },
      { "pillId": "d9_p12", "title": "Bloco 4: Documentação e Análise", "type": "sectionHeader", "content": "Duração: 1 Hora" },
      { "pillId": "d9_p13", "title": "Documentação (README.md)", "type": "code", "language": "markdown", "content": "# Missão\nConstruir um protótipo de um Agente de IA com parsing robusto e ferramentas integradas.\n\n# Arquitetura\n(Insira o seu diagrama de fluxo do agente).\n\n# Componentes do Agente\n- **Cérebro:** gemini-pro.\n- **Ferramentas:** web_search, sentiment_analyzer, stock_price.\n- **Engenharia de Prompt:** Explique a abordagem de prompt modular.\n\n# Transcrição da Execução\n(Cole o output completo do agent.py).\n\n# Análise e Próximos Passos\n(Discuta as limitações e como evoluir para o Function Calling nativo do Gemini)." },
      { "pillId": "d9_p14", "title": "Commit e Push", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"feat(day-09): build and document a ReAct-based AI agent\"" },
      { "pillId": "d9_p15", "title": "Fim da Transmissão do Dia 9", "type": "finalAssessment", "content": "Operador, a missão de hoje foi um vislumbre do futuro, construído com o rigor da engenharia do presente. Você não apenas usou IA, você a orquestrou de forma robusta e modular. Você construiu um sistema que pode raciocinar, planejar e usar ferramentas, conectando múltiplos dias de trabalho num único fluxo coerente. Com esta última peça técnica no lugar, a sua transformação está quase completa. Você aprendeu a comandar, construir, refinar, automatizar e orquestrar. Só resta uma missão: consolidar as suas vitórias e apresentar a sua nova identidade ao mundo. Amanhã é o dia do lançamento. Prepare o seu portfólio. Missão cumprida. Descanse." }
    ]
  },
  {
    "id": "dia-10",
    "dayNumber": 10,
    "title": "Operação Capstone",
    "subtitle": "Síntese, Validação e Apresentação",
    "audioSummaryUrl": "",
    "contentPills": [
      { "pillId": "d10_p01", "title": "Filosofia do Dia", "type": "paragraph", "content": "Conhecimento é um mapa. Tutoriais são o campo de tiro. O Capstone é a sua primeira missão a solo. Mas a missão não termina quando a solução é construída. Ela termina quando o seu trabalho pode ser apresentado, defendido e validado perante os seus pares e superiores. Hoje, você consolida o seu arsenal para a inspeção final." },
      { "pillId": "d10_p02", "title": "Objetivo Estratégico", "type": "paragraph", "content": "Conceber e prototipar um projeto de IA do zero, aplicando as habilidades dos Dias 1-9. E, finalmente, sintetizar toda a jornada de 10 dias num portfólio profissional e preparar uma apresentação final para ser publicada e avaliada dentro da Plataforma Vórtex." },
      { "pillId": "d10_p03", "title": "Bloco 1: Definição da Missão (Planeamento do Capstone)", "type": "sectionHeader", "content": "Duração: 1.5 Horas" },
      { "pillId": "d10_p04", "title": "Bloco 2: Execução do Protótipo (Foco no MVP)", "type": "sectionHeader", "content": "Duração: 4 Horas" },
      { "pillId": "d10_p05", "title": "Bloco 3: Documentação Profissional do Capstone", "type": "sectionHeader", "content": "Duração: 2.5 Horas" },
      { "pillId": "d10_p06", "title": "Bloco 4: Consolidação do Dossiê e Preparação para Apresentação", "type": "sectionHeader", "content": "Duração: 2 Horas" },
      { "pillId": "d10_p07", "title": "Polimento do Portfólio no GitHub", "type": "subHeader", "content": "Crie um README.md na raiz do seu repositório. Este é o índice do seu dossiê." },
      { "pillId": "d10_p08", "title": "Estrutura do README Principal", "type": "code", "language": "markdown", "content": "# Portfólio de Engenharia de IA - Operador [Seu Nome/ID]\n\n## Declaração de Capacidade\nCapaz de projetar e implantar soluções de IA de ponta a ponta na stack Google Cloud, abrangendo o ciclo de vida completo: Engenharia de Prompt, Pipelines de Dados, Fine-Tuning de Modelos, Automação de MLOps e Arquitetura de Agentes.\n\n## Tabela de Missões\n| Dia | Missão | Habilidades Chave | Link |\n|---|---|---|---|\n| 1 | Arquitetura de Prompt | Engenharia de Prompt, JSON Schema | ./dia-01-... |\n|...|...|...|...|\n| 10| PROJETO CAPSTONE | Síntese, Arquitetura | ./dia-10-... |" },
      { "pillId": "d10_p09", "title": "Criação do Demo Interativo", "type": "subHeader", "content": "Crie um demo interativo para o seu projeto mais impactante usando Hugging Face Spaces com Gradio/Streamlit." },
      { "pillId": "d10_p10", "title": "Pílula de Conhecimento", "type": "knowledgePill", "content": "Um demo funcional e interativo é a forma mais rápida de provar o valor do seu trabalho. Permite que os avaliadores interajam com a sua criação sem precisar de clonar o seu repositório ou configurar um ambiente." },
      { "pillId": "d10_p11", "title": "Preparação do Briefing Final (Para a Plataforma Vórtex)", "type": "subHeader", "content": "Na raiz do seu repositório, crie um arquivo chamado VORTEX_SUBMISSION.md." },
      { "pillId": "d10_p12", "title": "Estrutura da Submissão Final", "type": "code", "language": "markdown", "content": "# Submissão Final - Operador [Seu Nome/ID]\n\n## Link para o Dossiê Completo (GitHub)\n[https://github.com/SEU_USUARIO/ia-bootcamp-portfolio](https://github.com/SEU_USUARIO/ia-bootcamp-portfolio)\n\n## Link para o Demo Interativo (Hugging Face Spaces)\n[URL_DO_SEU_DEMO_AQUI]\n\n---\n\n## Apresentação do Projeto Capstone: [Nome do seu Projeto]\n\n### 1. A Missão\n(Um parágrafo conciso explicando o problema que o seu projeto resolve.)\n\n### 2. A Arquitetura\n![Arquitetura do Capstone](./dia-10-capstone/architecture.png)\n*(Uma breve legenda explicando os principais componentes.)*\n\n### 3. Destaque Técnico Chave\n(Escolha UMA decisão técnica interessante que você tomou e explique o porquê.)\n\n### 4. Próximos Passos (Roadmap de Evolução)\n(Liste 2-3 próximos passos claros do seu README do Capstone.)\n\n---\n\n## Autoavaliação e Reflexão Final\n(Um parágrafo refletindo sobre a sua maior aprendizagem durante o bootcamp.)" },
      { "pillId": "d10_p13", "title": "O Commit Final", "type": "code", "language": "bash", "content": "git add .\ngit commit -m \"docs: prepare final submission for Vórtex Platform\"\ngit push origin main", "validationCriteria": { "prompt": "Cole a URL completa do seu repositório 'ia-bootcamp-portfolio' no GitHub:", "type": "url_matches_pattern", "pattern": "https://github.com/" } },
      { "pillId": "d10_p14", "title": "Fim da Transmissão do Dia 10", "type": "finalAssessment", "content": "Operador, hoje você não apenas provou a sua autonomia; você preparou o seu trabalho para o escrutínio profissional. Você consolidou as suas missões num dossiê coeso, criou uma prova de conceito interativa e formulou uma apresentação que articula não apenas o que você fez, mas por que o fez dessa forma. A campanha de 10 dias está completa. O seu portfólio está pronto. As suas habilidades foram validadas. A sua apresentação está preparada. A sua nova identidade como Engenheiro de IA do Vórtex foi conquistada. A sua missão agora é submeter este relatório final e aguardar a sua próxima designação. Missão Cumprida. Com distinção. Fim da transmissão." }
    ]
  }
]